{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193dedb9-06ac-4c8b-b72d-785f53360971",
   "metadata": {},
   "source": [
    "# 第6回\n",
    "\n",
    "## 前回の課題の補足\n",
    "\n",
    "一度パターンデータベースを構築したら、保存して再利用したい。\n",
    "Pythonの場合には pickle を使えば簡単に実現できる。\n",
    "C++ でも serialise, deserialise で同様のことが可能。\n",
    "以下の例の様にハッシュテーブル（だけでなくほぼ任意のデータ構造）をファイルに保存できる。\n",
    "保存したファイルを読み出せばそのままの状態で使える。\n",
    "以下を実行すると、実際に 'dict.pickle' というファイルが作られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba4a2f-b1af-4ae2-98e7-5715d7179d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pickle で hash table を保存/読込\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "dict = {}\n",
    "dict['a'] = 1\n",
    "dict['b'] = 2\n",
    "\n",
    "print(dict)\n",
    "\n",
    "# dict をファイルに保存\n",
    "with open('dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict, handle)\n",
    "\n",
    "# dict をファイルから読み出し\n",
    "with open('dict.pickle', 'rb') as handle:\n",
    "    dict2 = pickle.load(handle)\n",
    "\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643782a3-a745-4d2a-9959-d79239436e94",
   "metadata": {},
   "source": [
    "## 敵のいる場合の探索\n",
    "\n",
    "最短経路を探索しようとしている人や、パズルやゲームをプレイしているアルゴリズムなど、\n",
    "何らかの行動をする存在をまとめて **エージェント (agent)** と呼ぶ。\n",
    "今までに取り上げた問題は全て、エージェントが一人しかいない single agent の問題だった。\n",
    "\n",
    "エージェントが複数存在する multi agent の問題は当然ながら single agent の場合よりも複雑になる。\n",
    "特にエージェント間の利害が対立する場合は最適な行動というものの定義が既に難しい。\n",
    "一般の multi agent 問題は**ゲーム理論**の扱うテーマであり、本講義では深入りしない。\n",
    "しかしエージェントが2人までなら、特定の場合には厳密な最適解を探索によって発見することができる。\n",
    "\n",
    "### 二人ゼロ和完全情報ゲーム\n",
    "\n",
    "それが **二人ゼロ和ゲーム完全情報 (two-player zero-sum perfect-information game)** と言われる場合である。\n",
    "より正確には「有限」と「確定」を付けて二人ゼロ和有限確定完全情報ゲームと呼ぶこともある。\n",
    "以下の条件を満たすゲームのことを言う。\n",
    "\n",
    "- 2人のプレイヤーがプレイする (ここではmaxプレイヤーとminプレイヤーと呼ぶ)\n",
    "- ゼロ和 (zero-sum): maxプレイヤーが勝てば、minプレイヤーはその分だけ負ける\n",
    "- 完全情報: 隠された情報はなく、全てが両方のプレイヤーに見えている\n",
    "- 有限: 有限時間で終わる\n",
    "- 確定: サイコロなどの確率的な要素がない\n",
    "\n",
    "チェス、囲碁、将棋、オセロなどが代表例である。\n",
    "以下は三目並べ (tic-tac-toe) のゲーム木である。\n",
    "終局を示す節点には、先手 (maxプレイヤー) が勝ちなら +1、\n",
    "後手 (minプレイヤー) が勝ちなら -1、引き分けなら 0 のスコアがあるとしている。\n",
    "先手はスコアを最大化しようとし、後手はスコアを最小化しようとするので\n",
    "それぞれ max プレイヤー、minプレイヤーと呼ぶ。\n",
    "\n",
    "<img src=\"tictactoe.png\" width=600>\n",
    "\n",
    "このようなゲーム木も初期局面をスタート節点とするグラフであり、\n",
    "直感的にはこのグラフを探索すれば最善手を求めることができそうに思える。\n",
    "しかし今までに扱ってきたA\\*探索などのアルゴリズムではそれはできない。\n",
    "この場合には相手のプレイヤーの存在を考慮したアルゴリズムが必要となる。\n",
    "\n",
    "## MiniMax探索 (MiniMax search)\n",
    "\n",
    "まず、以下の仮想的なゲーム木を見てみよう。\n",
    "初期局面から初めて3手で終わるゲームであり、末端の節点にスコアが示されている。\n",
    "max nodeから出る辺はmaxプレイヤーの着手を示す。min node から出る辺は min プレイヤーの着手である。\n",
    "この場合、双方のプレイヤーが最善を尽くしたら最終的なスコアはどうなるだろうか。\n",
    "\n",
    "<img src=\"minimax.gif\" width=600>\n",
    "\n",
    "この図では左側の辺から順番にたどって深さ優先探索を行ってスコアを求めている。\n",
    "1. max プレイヤーはスコアを最大化したい。\n",
    "    末端まで探索し、50と24の大きい方を選ぶ。その右側では70を選ぶ。\n",
    "1. min プレイヤーはスコアを最小化したい。\n",
    "    50と70が判明した時点でその小さい方、50を選ぶ。\n",
    "1. 以下繰り返す\n",
    "\n",
    "ここで示したものが minimax 探索、min-max 探索などと呼ばれるアルゴリズムの動作である。\n",
    "補足だが、二人ゲームの場合には、探索の開始節点を **根節点 (root)**\n",
    "辺を **着手 (move)** と呼ぶことが多い。\n",
    "また、終局した状態 (どちらかの勝ちか引き分け) の節点を **終端節点 (terminal node)** あるいは\n",
    "単に終端 （terminal) と言う。\n",
    "\n",
    "以下にminimax探索の疑似コードを示す。\n",
    "MaxSearch, MinSearchを交互に呼び出す再帰呼び出しでの例である。\n",
    "MaxSearch は先手プレイヤーの手番での探索で、最大の値を得ようとする。\n",
    "MinSearch は逆に最小の値を得ようとする。\n",
    "\n",
    "```\n",
    "fun MinimaxSearch(game, state) {\n",
    "  player = Max_player\n",
    "  value, move = MaxSearch(game, state)\n",
    "}\n",
    "\n",
    "fun MaxSearch(game, state) {\n",
    "  if (state is terminal) { return state.score }\n",
    "  best_val = -inf\n",
    "  best_move = dummy\n",
    "  for each move at state {\n",
    "    next_state = game.make_move(state, move)\n",
    "    val = MinSearch(game, next_state)\n",
    "    if (val > best_val) {\n",
    "      best_val = val\n",
    "      best_move = move\n",
    "    }\n",
    "  }\n",
    "  return (best_val, best_move)\n",
    "}\n",
    "\n",
    "fun MinSearch(game, state) {\n",
    "  if (state is terminal) { return state.score }\n",
    "  best_val = +inf\n",
    "  best_move = dummy\n",
    "  for each move at state {\n",
    "    next_state = game.make_move(state, move)\n",
    "    val = MaxSearch(game, next_state)\n",
    "    if (val < best_val) {\n",
    "      best_val = val\n",
    "      best_move = move\n",
    "    }\n",
    "  }\n",
    "  return (best_val, best_move)\n",
    "}\n",
    "```\n",
    "\n",
    "細かいところだが、スコアを返すときにプラスマイナスを反転すると\n",
    "MaxSearchとMinSearchを同じコードで実装することができ、\n",
    "それを NegaMax と呼ぶことがある。\n",
    "実際に MiniMax 探索を実装する際には NegaMax にするのが普通である。\n",
    "以下がNegaMaxの疑似コードである。\n",
    "注意点としては、NegaMaxを再帰呼び出しするときにその正負を反転すること、\n",
    "スコアを返すときにその時点の player の視点からのスコアを返すことの2点である。\n",
    "\n",
    "```\n",
    "fun NegaMaxSearch(game, state) {\n",
    "  player = Max_player\n",
    "  value, move = NegaMax(game, state, player)\n",
    "}\n",
    "\n",
    "fun NegaMax(game, player) {\n",
    "  if (state is terminal) { return evaluate(state, player) }\n",
    "  best_val = -inf\n",
    "  best_move = dummy\n",
    "  for each move at state {\n",
    "    next_state = game.make_move(state, move)\n",
    "    next_player = flip(player)\n",
    "    val = -NegaMax(game, next_state, next_player)\n",
    "    if (val > best_val) {\n",
    "      best_val = val\n",
    "      best_move = move\n",
    "    }\n",
    "  }\n",
    "  return (best_val, best_move)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18e0ae-e5bc-4dae-80f1-01d1a8557922",
   "metadata": {},
   "source": [
    "### Alpha-Beta 枝刈り (Alpha-Beta探索)\n",
    "\n",
    "先ほど示した MiniMax 探索は色々と無駄がある。\n",
    "簡単に分かる点としては、探索中に val に +1 が返ってきたら、その先を探索しなくても勝ちは決まっているので省略して良い。\n",
    "しかし探索の動作をよく観察すると、探索しなくて良い場合がさらに存在することが分かる。\n",
    "詳しくは以下の図で説明するが、一言で言えば良すぎる手、悪すぎる手を枝刈りできるということである。\n",
    "良すぎる手を刈る alpha 枝刈り、悪すぎる手を刈る beta 枝刈りを行うので\n",
    "これを Alpha-Beta 枝刈り (Alpha-Beta pruning) と言う。\n",
    "さらにこれを用いる Minimax探索を **AlphaBeta探索** と言う。\n",
    "\n",
    "<img src=\"alphabeta.gif\" width=600>\n",
    "\n",
    "評価値が**window**の中にあるなら良すぎも悪すぎもしない。\n",
    "逆にwindowの外にある値が返ったら即座に枝刈りされる。\n",
    "\n",
    "<img src=\"alphabetawindow.png\" width=600>\n",
    "\n",
    "以下に疑似コードを示す。\n",
    "関数NegaAlphaBetaの最後の二つの引数が上記の window を示す。\n",
    "最初は $ [-inf, +inf] $ である。\n",
    "探索中に、自分の手番からは最低限 alpha_value 以上を返せることになるので\n",
    "より高いスコアが返ってきたらそれで alpha_value を更新している。\n",
    "また、beta_value より高い値が返ってきたらそれは良すぎることを意味するので\n",
    "それ以上の探索を打ち切り、即座に return する。\n",
    "\n",
    "```\n",
    "fun AlphaBetaSearch(game, state) {\n",
    "  player = Max_player\n",
    "  value, move = NegaAlphaBeta(game, state, -inf, +inf)\n",
    "}\n",
    "\n",
    "fun NegaAlphaBeta(game, player, alpha_value, beta_value) {\n",
    "  if (state is terminal) { return evaluate(state, player) }\n",
    "  best_val = -inf\n",
    "  best_move = dummy\n",
    "  for each move at state {\n",
    "    next_state = game.make_move(state, move)\n",
    "    next_player = flip(player)\n",
    "    val = -NegaAlphaBeta(game, next_state, -beta_value, -alpha_value)\n",
    "    if (val > best_val) {\n",
    "      best_val = val\n",
    "      best_move = move\n",
    "      alpha_value = Max(alpha_value, val)\n",
    "    }\n",
    "    if (val >= beta) { return (val, move) }\n",
    "  }\n",
    "  return (best_val, best_move)\n",
    "}\n",
    "```\n",
    "\n",
    "### 評価関数つき Alpha-Beta search (Heuristic Alpha-Beta search)\n",
    "\n",
    "ここまで例では、ゲームのスコアを実際に末端 (terminal) まで探索して求めていた。\n",
    "この方法では探索空間の小さいゲームは良いが、ある程度以上大きいゲームは解けない。\n",
    "そこで、末端まで探索するのではなく、ある程度の深さまで探索してそこで\n",
    "**評価関数 (evaluation function)** を呼ぶ方法がある。\n",
    "評価関数は実際のゲームのスコアを近似して予測する何らかの関数である。\n",
    "\n",
    "ある程度正確な評価関数を作成すれば、深く探索することでかなり強い\n",
    "プログラムを作成することが可能だ。\n",
    "チェスなどでは人間がプログラムした (hand-craftedな) 評価関数と Alpha-Beta探索で\n",
    "世界チャンピオンにコンピュータが勝利している。\n",
    "将棋などでは機械学習で作られた評価関数を用いてやはりコンピュータが人間を超える強さを獲得している。\n",
    "評価関数の作成は容易ではないことが多く、興味深いテーマだが\n",
    "本講義では説明時間が足りないため詳細には触れない。\n",
    "\n",
    "### その他のテクニック\n",
    "\n",
    "3目並べのゲーム木を見れば明らかだが、ゲームの探索空間では合流が起きることがある。\n",
    "上で示した疑似コードは合流に対応していないためこの点も無駄である。\n",
    "しかしMiniMax探索やAlpha-Beta探索も、ハッシュテーブルを使って同じ節点を再展開することを回避できる。\n",
    "\n",
    "また評価関数を使った Alpha-Beta探索の場合に特に反復深化も使われる。\n",
    "浅い探索はすぐに終了するため、深さを徐々に増やしながら探索を行うことで\n",
    "ある程度の Anytime性を得ることもできる。\n",
    "制限時間内に着手する必要のある対戦などではこの点も重要だ。\n",
    "\n",
    "探索の深さについては、有望な手は深く、そうでないところは浅く探索するように制御される。\n",
    "これもプログラムの強さのためには非常に重要なテクニックである。\n",
    "人工知能の世界では長らくチェス等が知性の象徴とみなされていたため、\n",
    "Alpha-Beta探索の技術はかなり発展した。\n",
    "\n",
    "\n",
    "二人ゼロ和ゲーム\n",
    "参考:\n",
    "https://qiita.com/thun-c/items/058743a25c37c87b8aa4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28249162-9c47-409c-94ac-dfb8765792cd",
   "metadata": {},
   "source": [
    "### 第6回課題\n",
    "- 6-1. 3目並べを Minimax探索または Alpha-Beta 探索で解け。適当な盤面を与えて、勝敗と最善手を正しく表示することを確かめよ。\n",
    "    以下のサンプルコードを利用しても良い。\n",
    "- 6-2. (発展課題) connect-four (重力付き4目並べ) を Alpha-Beta 探索で解くプログラムを書き、適当な初期盤面から正しく動作することを確かめよ。  \n",
    "    https://en.wikipedia.org/wiki/Connect_Four  \n",
    "    https://ja.wikipedia.org/wiki/%E5%9B%9B%E7%9B%AE%E4%B8%A6%E3%81%B9  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f1048-aaeb-4e4f-8b9b-bf9db27b494a",
   "metadata": {},
   "source": [
    "## 講義アンケート回答について\n",
    "\n",
    "```\n",
    "講義アンケートは　６月１７日（金）までに回答するようにご指示ください．\n",
    "\n",
    "※※※※※　アンケートの方法　※※※※※\n",
    "\n",
    "Moodleの「2022年度授業アンケート(2022 Course evaluation questionnaire)」\n",
    "https://moodle.s.kyushu-u.ac.jp/course/view.php?id=40030\n",
    "へアクセスし（SSO-KIDでのログインが必要です），以下の項目のリンクをクリックしてください．\n",
    "\n",
    "2022年度春学期 大学院システム情報科学府授業アンケート: Questionnaire for ISEE Courses, Spring Quarter, 2022\n",
    "\n",
    "科目名と担当教員の一覧が表示されますので，回答する科目を選択し，回答してください．\n",
    "\n",
    "※※※※※※※※※※※※※※※※※※※※\n",
    "```\n",
    "\n",
    "参考文献\n",
    "1. \"Artificial Intelligence: A Modern Approach, 4th Global ed.\", by Stuart Russell and Peter Norvig  \n",
    "   http://aima.cs.berkeley.edu/index.html\n",
    "1. \"ヒューリスティック探索入門\", 陣内 佑  \n",
    "   https://jinnaiyuu.github.io/pdf/textbook.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6859438b-2107-4680-b1b1-435fa922ae86",
   "metadata": {},
   "source": [
    "# 課題1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9949d14-4f9f-4f75-be2d-cba71e2cecce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, [0, 0])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        player_id = 0 (X) or 1 (O)\n",
    "        initial state\n",
    "        [[' ',' ',' '],\n",
    "         [' ',' ',' '],\n",
    "         [' ',' ',' ']]                           \n",
    "        '''\n",
    "        self.players = ['X', 'O']\n",
    "        \n",
    "    def is_terminal(self, state):\n",
    "        '''\n",
    "        return true if state is terminal\n",
    "        '''\n",
    "        if self.is_draw(state):\n",
    "            return True\n",
    "        elif self.is_win(state,0) or self.is_win(state,1):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_draw(self, state):\n",
    "        '''\n",
    "        state が引き分けかどうか判定する関数を実装せよ\n",
    "        '''\n",
    "        if self.is_win(state,0) or self.is_win(state,1):\n",
    "            return False\n",
    "        for i in state:\n",
    "            for j in i:\n",
    "                if j==' ':\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def is_win(self, state, player_id):\n",
    "        '''\n",
    "        state と player から勝ちを判定する関数を実装せよ\n",
    "        '''\n",
    "        a=self.players[player_id]\n",
    "        li=[]\n",
    "        for i in range(3):\n",
    "            if state[i]==[a,a,a]:\n",
    "                return True\n",
    "            for j in range(3):\n",
    "                if state[i][j]==a:\n",
    "                    li.append([i,j])\n",
    "        pat=[[[i,j] for i in [0,1,2]] for j in [0,1,2]] +[[[0,0],[1,1],[2,2]]]+[[[0,2],[1,1],[2,0]]]\n",
    "        for i in pat:\n",
    "            x=0\n",
    "            for j in i:\n",
    "                if j in li:\n",
    "                    x+=1\n",
    "            if x==3:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def make_move(self, state, move, player_id):\n",
    "        '''\n",
    "        return next state\n",
    "        '''\n",
    "        new_state = copy.deepcopy(state)\n",
    "        x, y = move\n",
    "        char = self.players[player_id]\n",
    "        new_state[x][y] = char\n",
    "        return new_state\n",
    "\n",
    "    def NegaMax(self, state, player_id):\n",
    "        if self.is_draw(state):\n",
    "            return 0,[]\n",
    "        elif self.is_win(state, player_id):\n",
    "            return 1,[]\n",
    "        elif self.is_win(state, 1 - player_id):\n",
    "            return -1,[]\n",
    "        \n",
    "        best_value = -100\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i][j]==' ':\n",
    "                    next_state = self.make_move(state, [i,j],player_id)\n",
    "                    next_player = 1-player_id\n",
    "                    val, move1= self.NegaMax(next_state, next_player)\n",
    "                    val=-val\n",
    "                    if val > best_value:\n",
    "                        best_value = val\n",
    "                        best_move = [i,j]\n",
    "        return best_value,best_move\n",
    "    \n",
    "    def Score(self):\n",
    "        return NegaMax(self.state, self.first_player)\n",
    "    \n",
    "game = TicTacToe()\n",
    "# root_state = [[' ',' ',' '],\n",
    "#              [' ',' ',' '],\n",
    "#              [' ',' ',' ']]                           \n",
    "root_state = [[' ',' ','X'],\n",
    "              [' ','O',' '],\n",
    "              ['X',' ','O']]                           \n",
    "\n",
    "score = game.NegaMax(root_state, 0)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d028ffa2-e020-45e3-9bd1-14744bd4bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ']\n",
      "[' ', ' ', ' ']\n",
      "[' ', ' ', ' ']\n",
      "--------------------\n",
      "['X', ' ', ' ']\n",
      "[' ', ' ', ' ']\n",
      "[' ', ' ', ' ']\n",
      "--------------------\n",
      "['X', ' ', ' ']\n",
      "[' ', 'O', ' ']\n",
      "[' ', ' ', ' ']\n",
      "--------------------\n",
      "['X', 'X', ' ']\n",
      "[' ', 'O', ' ']\n",
      "[' ', ' ', ' ']\n",
      "--------------------\n",
      "['X', 'X', 'O']\n",
      "[' ', 'O', ' ']\n",
      "[' ', ' ', ' ']\n",
      "--------------------\n",
      "['X', 'X', 'O']\n",
      "[' ', 'O', ' ']\n",
      "['X', ' ', ' ']\n",
      "--------------------\n",
      "['X', 'X', 'O']\n",
      "['O', 'O', ' ']\n",
      "['X', ' ', ' ']\n",
      "--------------------\n",
      "['X', 'X', 'O']\n",
      "['O', 'O', 'X']\n",
      "['X', ' ', ' ']\n",
      "--------------------\n",
      "['X', 'X', 'O']\n",
      "['O', 'O', 'X']\n",
      "['X', 'O', ' ']\n",
      "--------------------\n",
      "['X', 'X', 'O']\n",
      "['O', 'O', 'X']\n",
      "['X', 'O', 'X']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def show(state):\n",
    "    for i in state:\n",
    "        print(i)\n",
    "    print('--------------------')\n",
    "\n",
    "    \n",
    "game = TicTacToe()\n",
    "root_state = [[' ',' ',' '],\n",
    "             [' ',' ',' '],\n",
    "             [' ',' ',' ']]                           \n",
    "# root_state = [[' ',' ','X'],\n",
    "#               [' ','O',' '],\n",
    "#               ['X',' ','O']]\n",
    "player=0\n",
    "while not game.is_terminal(root_state):\n",
    "    show(root_state)\n",
    "    score = game.NegaMax(root_state, player)\n",
    "    root_state[score[1][0]][score[1][1]]=game.players[player]\n",
    "    player=1-player\n",
    "show(root_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ebd24ac-b842-47dc-9576-ce7754f74094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When one side is in a sure-to-lose state, it moves randomly.  \n",
    "# eg: \n",
    "# _ O _\n",
    "# X _ _\n",
    "# _ _ _"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee86934-2980-42fa-a27c-ff0800ef73e4",
   "metadata": {},
   "source": [
    "# 課題2  \n",
    "connect-four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0b747e-9b9f-4961-b381-0ce558140fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class ConnectFour:\n",
    "    def __init__(self):\n",
    "        # 7x6\n",
    "        self.players = ['X', 'O']\n",
    "        \n",
    "    def is_terminal(self, state):\n",
    "        if self.is_draw(state):\n",
    "            return True\n",
    "        elif self.is_win(state,0) or self.is_win(state,1):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_draw(self, state):\n",
    "        if self.is_win(state,0) or self.is_win(state,1):\n",
    "            return False\n",
    "        for i in range(7):\n",
    "            if state[i][0]==' ':\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def is_win(self, state, player_id):\n",
    "        li=[]\n",
    "        for i in range(7):\n",
    "            for j in range(6):\n",
    "                if state[i][j]==self.players[player_id]:\n",
    "                    li.append([i,j])\n",
    "        for i in li:\n",
    "            if [i[0]+1,i[1]] in li and [i[0]+2,i[1]] in li and [i[0]+3,i[1]] in li:\n",
    "                return True\n",
    "            if [i[0],i[1]+1] in li and [i[0],i[1]+2] in li and [i[0],i[1]+3] in li:\n",
    "                return True\n",
    "            if [i[0]+1,i[1]+1] in li and [i[0]+2,i[1]+2] in li and [i[0]+3,i[1]+3] in li:\n",
    "                return True\n",
    "            if [i[0]-1,i[1]+1] in li and [i[0]-2,i[1]+2] in li and [i[0]-3,i[1]+3] in li:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def make_move(self, state, move, player_id):\n",
    "        new_state = copy.deepcopy(state)\n",
    "        for i in range(6):\n",
    "            if state[move][i]!=' ':\n",
    "                char = self.players[player_id]\n",
    "                new_state[move][i-1] = char\n",
    "                return new_state\n",
    "    \n",
    "    \n",
    "\n",
    "    def show(self,state):\n",
    "        for i in state:\n",
    "            print(i)\n",
    "        print('-------------------------------------')\n",
    "    \n",
    "    def NegaAlphaBeta(self,state, player_id, alpha_value, beta_value):\n",
    "        if self.is_draw(state):\n",
    "            return 0,[]\n",
    "        elif self.is_win(state, player_id):\n",
    "            return 1,[]\n",
    "        elif self.is_win(state, 1 - player_id):\n",
    "            return -1,[]\n",
    "        \n",
    "        best_value = -100\n",
    "        for i in range(7):\n",
    "            if state[i][0]==' ':\n",
    "                next_state = self.make_move(state, i, player_id)\n",
    "                next_player = 1-player_id\n",
    "                val, move1= self.NegaAlphaBeta(next_state, next_player,-beta_value,-alpha_value)\n",
    "                val=-val\n",
    "                if val > best_value:\n",
    "                    best_value = val\n",
    "                    best_move = i\n",
    "                    alpha_value = max(alpha_value, val)\n",
    "                if val>=beta_value:\n",
    "                    return val,move1\n",
    "        return best_value,best_move\n",
    "    \n",
    "    def Score(self):\n",
    "        return NegaAlphaBeta(self.state, self.first_player,-100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f70ef3c1-8426-4ab8-bae7-79f229d28141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 0)\n"
     ]
    }
   ],
   "source": [
    "game = ConnectFour()                           \n",
    "root_state = [[' ',' ','O','X','X','X'],\n",
    "              [' ',' ',' ',' ','X','O'],\n",
    "              [' ',' ','O','X','X','X'],\n",
    "              ['O','X','O','O','O','X'],\n",
    "              [' ','O','O','X','X','X'],\n",
    "              [' ',' ',' ',' ','X','O'],\n",
    "              [' ','O','O','X','O','O']]                           \n",
    "\n",
    "score = game.NegaAlphaBeta(root_state, 0, -100, 100)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
